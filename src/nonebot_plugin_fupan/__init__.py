from nonebot import logger, require, on_command
from nonebot.permission import SUPERUSER
from nonebot.plugin import PluginMetadata, inherit_supported_adapters
from nonebot.params import CommandArg, Arg
from nonebot.typing import T_State
from nonebot.adapters import Message

require("nonebot_plugin_uninfo")
require("nonebot_plugin_localstore")
require("nonebot_plugin_apscheduler")
from .config import Config, plugin_config
from nonebot_plugin_uninfo import get_interface, Uninfo


__plugin_meta__ = PluginMetadata(
    name="å¤ç›˜æ‰“å¡",
    description="ç”¨äºäº¤æ˜“æ—¥å¤ç›˜æ‰“å¡ç­¾åˆ°çš„æ’ä»¶ï¼ˆæ”¯æŒç¾¤èŠ/ç§èŠæ•°æ®åˆ†ç¦»ï¼‰",
    usage="ä½¿ç”¨å‘½ä»¤ï¼šå¤ç›˜/æ‰“å¡/ç­¾åˆ° è¿›è¡Œæ¯æ—¥äº¤æ˜“åå¤ç›˜æ‰“å¡ï¼Œæ”¯æŒç¾¤èŠå’Œç§èŠç¯å¢ƒåˆ†åˆ«ç»Ÿè®¡",
    type="application",
    homepage="https://github.com/zanderzhng/nonebot-plugin-fupan",
    config=Config,
    supported_adapters=inherit_supported_adapters("nonebot_plugin_uninfo"),
    extra={"author": "zanderzhng <your@mail.com>"},
)

from datetime import datetime, time
import json
from typing import Optional
from pathlib import Path

from nonebot_plugin_localstore import get_data_file, get_data_dir, get_plugin_data_dir
import exchange_calendars as xcals


def get_current_datetime() -> datetime:
    """Get current datetime - can be mocked for testing"""
    return datetime.now()


# åˆå§‹åŒ–äº¤æ˜“æ‰€æ—¥å† (ä½¿ç”¨ä¸­å›½Aè‚¡æ—¥å†)
xcal = xcals.get_calendar('XSHG')  # ä¸Šæµ·è¯åˆ¸äº¤æ˜“æ‰€æ—¥å†

# åˆ›å»ºå¤ç›˜æ‰“å¡å‘½ä»¤ï¼Œæ”¯æŒå¤šä¸ªåˆ«å
fupan_checkin = on_command("å¤ç›˜", aliases={"æ‰“å¡", "ç­¾åˆ°"})

# ç»Ÿè®¡å‘½ä»¤
fupan_stats = on_command("å¤ç›˜ç»Ÿè®¡", aliases={"å¤ç›˜ stats"})

# æ’è¡Œå‘½ä»¤
fupan_rank = on_command("å¤ç›˜æ’è¡Œ", aliases={"å¤ç›˜ rank"})

# æ’¤é”€æ‰“å¡å‘½ä»¤
fupan_revoke = on_command("å¤ç›˜æ’¤é”€", aliases={"æ’¤é”€å¤ç›˜"})

# æ•°æ®é‡ç½®å‘½ä»¤
fupan_reset = on_command("å¤ç›˜é‡ç½®")

# å¸®åŠ©å‘½ä»¤

def get_checkin_data_file(user_id: str, group_id: Optional[str] = None) -> Path:
    """è·å–ç”¨æˆ·æ‰“å¡æ•°æ®æ–‡ä»¶è·¯å¾„"""
    if group_id:
        data_dir = get_plugin_data_dir()
        path = data_dir / f"checkin_{user_id}_group_{group_id}.json"
        # logger.debug(f"Group data file path: {path}")
        return path
    else:
        data_dir = get_plugin_data_dir()
        path = data_dir / f"checkin_{user_id}_dm.json"
        # logger.debug(f"DM data file path: {path}")
        # logger.debug(f"Data directory: {path.parent}")
        return path

def get_all_checkin_files() -> list[Path]:
    """è·å–æ‰€æœ‰ç”¨æˆ·çš„æ‰“å¡æ•°æ®æ–‡ä»¶"""
    data_dir = get_plugin_data_dir()
    return list(data_dir.glob("checkin_*.json"))

def load_user_checkin_data(user_id: str, group_id: Optional[str] = None) -> dict:
    """åŠ è½½ç”¨æˆ·æ‰“å¡æ•°æ®"""
    data_file = get_checkin_data_file(user_id, group_id)
    if data_file.exists():
        with open(data_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            # Ensure strike_count field exists for backward compatibility
            if "strike_count" not in data:
                data["strike_count"] = 0
            return data
    return {"user_id": user_id, "nickname": "", "checkins": [], "total_count": 0, "strike_count": 0}

def save_user_checkin_data(user_id: str, data: dict, group_id: Optional[str] = None):
    """ä¿å­˜ç”¨æˆ·æ‰“å¡æ•°æ®"""
    data_file = get_checkin_data_file(user_id, group_id)
    # Ensure parent directory exists
    data_file.parent.mkdir(parents=True, exist_ok=True)
    with open(data_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def reset_group_data(group_id: str) -> int:
    """é‡ç½®æŒ‡å®šç¾¤ç»„çš„æ‰€æœ‰ç”¨æˆ·æ•°æ®"""
    all_files = get_all_checkin_files()
    reset_count = 0

    # åˆ é™¤æŒ‡å®šç¾¤ç»„çš„æ‰€æœ‰ç”¨æˆ·æ•°æ®æ–‡ä»¶
    for file_path in all_files:
        if f"_group_{group_id}.json" in file_path.name:
            file_path.unlink()
            reset_count += 1

    return reset_count


def reset_all_dm_data() -> int:
    """é‡ç½®æ‰€æœ‰ç§èŠç”¨æˆ·æ•°æ®"""
    all_files = get_all_checkin_files()
    reset_count = 0

    # åˆ é™¤æ‰€æœ‰ç§èŠç”¨æˆ·æ•°æ®æ–‡ä»¶
    for file_path in all_files:
        if file_path.name.endswith("_dm.json"):
            file_path.unlink()
            reset_count += 1

    return reset_count

def is_trading_day(date: datetime) -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸ºäº¤æ˜“æ—¥"""
    return xcal.is_session(date.date())

def get_previous_trading_day(date: datetime) -> Optional[datetime]:
    """è·å–å‰ä¸€ä¸ªäº¤æ˜“æ—¥"""
    previous_sessions = xcal.previous_session(date.date())
    if previous_sessions:
        return datetime.combine(previous_sessions, time())
    return None

def get_next_trading_day(date: datetime) -> Optional[datetime]:
    """è·å–ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥"""
    next_sessions = xcal.next_session(date.date())
    if next_sessions:
        return datetime.combine(next_sessions, time())
    return None



def get_time_window_for_context(user_id: str, group_id: Optional[str] = None) -> tuple[str, str]:
    """è·å–æŒ‡å®šç”¨æˆ·æˆ–ç¾¤ç»„çš„æ—¶é—´çª—å£é…ç½®"""
    # Check for group-specific configuration
    if group_id and hasattr(plugin_config, 'fupan_checkin_group_time_windows'):
        group_configs = plugin_config.fupan_checkin_group_time_windows
        if group_id in group_configs:
            group_config = group_configs[group_id]
            if 'start_time' in group_config and 'end_time' in group_config:
                return group_config['start_time'], group_config['end_time']

    # Check for user-specific configuration
    if hasattr(plugin_config, 'fupan_checkin_user_time_windows'):
        user_configs = plugin_config.fupan_checkin_user_time_windows
        if user_id in user_configs:
            user_config = user_configs[user_id]
            if 'start_time' in user_config and 'end_time' in user_config:
                return user_config['start_time'], user_config['end_time']

    # Fall back to global configuration
    return plugin_config.fupan_checkin_start_time, plugin_config.fupan_checkin_end_time

def get_current_trading_status(user_id: str, group_id: Optional[str] = None, now: Optional[datetime] = None) -> dict:
    """è·å–å½“å‰äº¤æ˜“çŠ¶æ€ï¼Œæ”¯æŒ per-group/per-user é…ç½®"""
    if now is None:
        now = get_current_datetime()
    today = now.date()

    # è·å–ç”¨æˆ·æˆ–ç¾¤ç»„ç‰¹å®šçš„æ—¶é—´çª—å£é…ç½®
    start_time_str, end_time_str = get_time_window_for_context(user_id, group_id)

    # åˆ¤æ–­ä»Šå¤©æ˜¯å¦ä¸ºäº¤æ˜“æ—¥
    is_today_trading = is_trading_day(now)

    if is_today_trading:
        # è·å–ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥
        next_trading_day = get_next_trading_day(now)

        start_time = datetime.strptime(start_time_str, "%H:%M").time()
        end_time = datetime.strptime(end_time_str, "%H:%M").time()

        # æ„å»ºæ£€æŸ¥æ—¶é—´çª—å£ (ç›˜åæ—¶é—´çª—å£)
        # ç›˜åå®šä¹‰ä¸ºï¼šTæ—¥æ”¶ç›˜ååˆ°T+1äº¤æ˜“æ—¥å¼€ç›˜å‰
        checkin_start = datetime.combine(today, start_time)
        # å¦‚æœç»“æŸæ—¶é—´æ˜¯ç¬¬äºŒå¤©ï¼Œåˆ™éœ€è¦åŠ ä¸Šä¸€å¤©
        if end_time < start_time:
            checkin_end = datetime.combine(next_trading_day.date() if next_trading_day else today, end_time)
        else:
            checkin_end = datetime.combine(today, end_time)

        # åˆ¤æ–­å½“å‰æ˜¯å¦åœ¨æ‰“å¡æ—¶é—´çª—å£å†…
        is_in_checkin_window = checkin_start <= now <= checkin_end

        return {
            "is_trading_day": True,
            "is_in_checkin_window": is_in_checkin_window,
            "checkin_start": checkin_start,
            "checkin_end": checkin_end,
            "next_trading_day": next_trading_day,
            "current_time": now
        }
    else:
        # ä»Šå¤©ä¸æ˜¯äº¤æ˜“æ—¥ï¼Œè·å–ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥
        next_trading_day = get_next_trading_day(now)
        if next_trading_day:
            # è·å–ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥çš„å‰ä¸€äº¤æ˜“æ—¥ï¼ˆå³æœ€è¿‘çš„äº¤æ˜“æ—¥ï¼‰
            previous_trading_day = get_previous_trading_day(next_trading_day)

            if previous_trading_day:
                # ä½¿ç”¨æœ€è¿‘äº¤æ˜“æ—¥ä½œä¸ºå‚è€ƒæ¥æ„å»ºæ—¶é—´çª—å£
                start_time = datetime.strptime(start_time_str, "%H:%M").time()
                end_time = datetime.strptime(end_time_str, "%H:%M").time()

                # æ„å»ºæ£€æŸ¥æ—¶é—´çª—å£ï¼ˆåŸºäºæœ€è¿‘çš„äº¤æ˜“æ—¥ï¼‰
                checkin_start = datetime.combine(previous_trading_day.date(), start_time)
                checkin_end = datetime.combine(next_trading_day.date(), end_time)

                # åˆ¤æ–­å½“å‰æ˜¯å¦åœ¨æ‰“å¡æ—¶é—´çª—å£å†…
                is_in_checkin_window = checkin_start <= now <= checkin_end

                return {
                    "is_trading_day": False,
                    "is_in_checkin_window": is_in_checkin_window,
                    "checkin_start": checkin_start,
                    "checkin_end": checkin_end,
                    "next_trading_day": next_trading_day,
                    "current_time": now
                }

        return {
            "is_trading_day": False,
            "is_in_checkin_window": False,
            "checkin_start": None,
            "checkin_end": None,
            "next_trading_day": next_trading_day,
            "current_time": now
        }

async def can_user_checkin(user_id: str, group_id: Optional[str] = None, now: Optional[datetime] = None) -> tuple[bool, str]:
    """æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å¯ä»¥æ‰“å¡"""
    if now is None:
        now = get_current_datetime()

    # æ£€æŸ¥æ—¶é—´çª—å£
    status = get_current_trading_status(user_id, group_id, now=now)

    if not status["is_in_checkin_window"]:
        if status["checkin_start"] and status["checkin_end"]:
            return False, f"ä¸åœ¨æ‰“å¡æ—¶é—´çª—å£å†…ï¼Œè¯·åœ¨ {status['checkin_start'].strftime('%H:%M')} - {status['checkin_end'].strftime('%mæœˆ%dæ—¥ %H:%M')} ä¹‹é—´æ‰“å¡"
        else:
            return False, "ä»Šå¤©ä¸æ˜¯äº¤æ˜“æ—¥ï¼Œä¸”æœªæ‰¾åˆ°åˆé€‚çš„æ‰“å¡æ—¶é—´çª—å£"

    # æ£€æŸ¥ä»Šæ—¥æ˜¯å¦å·²æ‰“å¡
    user_data = load_user_checkin_data(user_id, group_id)
    today_str = now.strftime("%Y-%m-%d")

    for checkin in user_data["checkins"]:
        if checkin["date"] == today_str:
            # è·å–å½“å‰å’Œä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥ä¿¡æ¯
            current_trading_day = now.date()
            # å¦‚æœä»Šå¤©æ˜¯äº¤æ˜“æ—¥ï¼Œåˆ™æ˜¾ç¤ºä»Šå¤©çš„æ—¥æœŸä½œä¸ºå½“å‰äº¤æ˜“æ—¥
            if is_trading_day(now):
                current_trading_day_str = current_trading_day.strftime("%Yå¹´%mæœˆ%dæ—¥")
            else:
                # å¦‚æœä»Šå¤©ä¸æ˜¯äº¤æ˜“æ—¥ï¼Œè·å–æœ€è¿‘çš„äº¤æ˜“æ—¥
                previous_trading_day = get_previous_trading_day(now)
                current_trading_day_str = previous_trading_day.strftime("%Yå¹´%mæœˆ%dæ—¥") if previous_trading_day else "æœªçŸ¥"

            next_trading_day = get_next_trading_day(now)
            next_trading_day_str = next_trading_day.strftime("%Yå¹´%mæœˆ%dæ—¥") if next_trading_day else "æœªçŸ¥"

            return False, f"äº¤æ˜“æ—¥ï¼ˆ{current_trading_day_str}ï¼‰å·²å¤ç›˜\nä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥ï¼š{next_trading_day_str}"

    return True, "å¯ä»¥æ‰“å¡"

@fupan_checkin.handle()
async def handle_fupan_checkin(state: T_State, uniinfo: Uninfo = Arg(), args: Message = CommandArg()):
    """å¤„ç†å¤ç›˜æ‰“å¡å‘½ä»¤"""
    # è·å–å½“å‰æ—¶é—´æˆ³ï¼Œå¯è¢«æµ‹è¯•mock
    now = get_current_datetime()

    # è·å–ç”¨æˆ·å’Œç¾¤ç»„ä¿¡æ¯
    user_id = str(uniinfo.user.id) if uniinfo.user else "unknown"
    group_id = str(uniinfo.scene.id) if uniinfo.scene and uniinfo.scene.is_group else None

    # è·å–ç”¨æˆ·æ˜µç§°ï¼Œå‚è€ƒæ­£ç¡®çš„Uninfoä½¿ç”¨æ–¹å¼
    nickname = user_id
    if uniinfo.user:
        # ä¼˜å…ˆä½¿ç”¨member.nickä½œä¸ºæ˜µç§°ï¼ˆå¦‚æœåœ¨ç¾¤ç»„ä¸­ï¼‰
        if uniinfo.member and hasattr(uniinfo.member, 'nick') and uniinfo.member.nick:
            nickname = uniinfo.member.nick
        # å¦‚æœæ²¡æœ‰member.nickï¼Œå°è¯•ä½¿ç”¨user.name
        elif hasattr(uniinfo.user, 'name') and uniinfo.user.name:
            nickname = uniinfo.user.name

    # è·å–ç»“è®ºæ–‡æœ¬ï¼ˆå¦‚æœæœ‰ï¼‰
    conclusion = args.extract_plain_text().strip()

    # æ£€æŸ¥æ˜¯å¦å¯ä»¥æ‰“å¡
    can_checkin, message = await can_user_checkin(user_id, group_id, now=now)

    if not can_checkin:
        await fupan_checkin.finish(message)

    # æ‰§è¡Œæ‰“å¡
    user_data = load_user_checkin_data(user_id, group_id)
    # æ›´æ–°æ˜µç§°ä¿¡æ¯
    user_data["nickname"] = nickname
    today_str = now.strftime("%Y-%m-%d")
    current_timestamp = now.timestamp()
    current_time_str = now.strftime("%Y-%m-%d %H:%M:%S")

    # Determine which trading day this check-in is for
    trading_day = today_str
    next_trading_day_obj = None

    if not is_trading_day(now):
        # If today is not a trading day, this check-in is for the previous trading day
        previous_trading_day = get_previous_trading_day(now)
        if previous_trading_day:
            trading_day = previous_trading_day.strftime("%Y-%m-%d")
        # Get the next trading day after the trading day this check-in is for
        next_trading_day_obj = get_next_trading_day(previous_trading_day if previous_trading_day else now)
    else:
        # If today is a trading day, get the next trading day
        next_trading_day_obj = get_next_trading_day(now)

    next_trading_day_str = next_trading_day_obj.strftime("%Y-%m-%d") if next_trading_day_obj else None

    # æ·»åŠ æ‰“å¡è®°å½•ï¼ŒåŒ…å«æ›´å¤šè¯¦ç»†ä¿¡æ¯
    checkin_record = {
        "date": today_str,
        "timestamp": current_timestamp,
        "trading_day": trading_day,
        "next_trading_day": next_trading_day_str,
        "context": "group" if group_id else "private"
    }

    # æ·»åŠ ç»“è®ºæ–‡æœ¬ï¼ˆå¦‚æœæœ‰ï¼‰
    if conclusion:
        checkin_record["conclusion"] = conclusion

    # Update strike count efficiently by comparing with previous check-in
    if len(user_data["checkins"]) > 0:
        # Get the previous check-in (the one before we add the new one)
        previous_checkin = user_data["checkins"][-1]
        previous_next_trading_day = previous_checkin.get("next_trading_day")
        previous_trading_day = previous_checkin.get("trading_day")

        # Special case: if this check-in is for the same trading day as the previous one,
        # it doesn't change the strike count (same trading day)
        if trading_day == previous_trading_day:
            # Same trading day, strike count unchanged
            pass
        # If this check-in's trading day matches the previous check-in's next trading day,
        # it's a consecutive strike
        elif previous_next_trading_day and trading_day == previous_next_trading_day:
            user_data["strike_count"] += 1
        else:
            # If not consecutive, reset to 1 (this check-in starts a new streak)
            user_data["strike_count"] = 1
    else:
        # First check-in, start with strike count of 1
        user_data["strike_count"] = 1

    user_data["checkins"].append(checkin_record)
    user_data["total_count"] = len(user_data["checkins"])

    # ä¿å­˜æ•°æ®
    save_user_checkin_data(user_id, user_data, group_id)


    # è·å–å½“å‰å’Œä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥ä¿¡æ¯
    current_trading_day = now.date()
    # å¦‚æœä»Šå¤©æ˜¯äº¤æ˜“æ—¥ï¼Œåˆ™æ˜¾ç¤ºä»Šå¤©çš„æ—¥æœŸä½œä¸ºå½“å‰äº¤æ˜“æ—¥
    if is_trading_day(now):
        current_trading_day_str = current_trading_day.strftime("%Yå¹´%mæœˆ%dæ—¥")
    else:
        # å¦‚æœä»Šå¤©ä¸æ˜¯äº¤æ˜“æ—¥ï¼Œè·å–æœ€è¿‘çš„äº¤æ˜“æ—¥
        previous_trading_day = get_previous_trading_day(now)
        current_trading_day_str = previous_trading_day.strftime("%Yå¹´%mæœˆ%dæ—¥") if previous_trading_day else "æœªçŸ¥"

    next_trading_day = get_next_trading_day(now)
    next_trading_day_str = next_trading_day.strftime("%Yå¹´%mæœˆ%dæ—¥") if next_trading_day else "æœªçŸ¥"

    # å‘é€æˆåŠŸæ¶ˆæ¯ï¼ŒåŒ…å«å½“å‰å’Œä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥ä¿¡æ¯
    strike_count = user_data.get("strike_count", 0)
    success_msg = (f"âœ… å¤ç›˜æ‰“å¡æˆåŠŸï¼\n"
                  f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                  f"  æ‰“å¡æ—¶é—´ï¼š{current_time_str}\n"
                  f"  ç´¯è®¡æ‰“å¡ï¼š{user_data['total_count']}æ¬¡\n"
                  f"  è¿ç»­æ‰“å¡ï¼š{strike_count}è¿å‡»\n")

    # æ·»åŠ ç»“è®ºæ˜¾ç¤ºï¼ˆå¦‚æœæœ‰ï¼‰
    if conclusion:
        success_msg += f"  å¤ç›˜ç»“è®ºï¼š{conclusion}\n"

    success_msg += (f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                   f"  äº¤æ˜“æ—¥ï¼ˆ{current_trading_day_str}ï¼‰å·²å¤ç›˜\n"
                   f"  ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥ï¼š{next_trading_day_str}")
    await fupan_checkin.finish(success_msg)

# ç»Ÿè®¡å‘½ä»¤
@fupan_stats.handle()
async def handle_fupan_stats(uniinfo: Uninfo = Arg()):
    """å¤„ç†å¤ç›˜ç»Ÿè®¡å‘½ä»¤"""
    user_id = str(uniinfo.user.id) if uniinfo.user else "unknown"
    group_id = str(uniinfo.scene.id) if uniinfo.scene and uniinfo.scene.is_group else None
    user_data = load_user_checkin_data(user_id, group_id)
    context = "ç¾¤ç»„" if group_id else "ç§èŠ"

    # Get basic statistics
    total_checkins = user_data['total_count']
    strike_count = user_data.get("strike_count", 0)

    stats_msg = f"ğŸ“ˆ æ‚¨çš„{context}å¤ç›˜æ‰“å¡ç»Ÿè®¡\n"
    stats_msg += f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
    stats_msg += f"  æ€»æ‰“å¡æ¬¡æ•°ï¼š{total_checkins}æ¬¡\n"
    stats_msg += f"  è¿ç»­æ‰“å¡æ¬¡æ•°ï¼š{strike_count}è¿å‡»\n"
    stats_msg += f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"

    # Add recent check-in history (last 10)
    if user_data["checkins"]:
        stats_msg += "ğŸ“š æœ€è¿‘æ‰“å¡è®°å½•ï¼š\n"
        # Sort checkins by date descending to show most recent first
        sorted_checkins = sorted(user_data["checkins"], key=lambda x: x["date"], reverse=True)
        for i, checkin in enumerate(sorted_checkins[:10]):  # Show last 10
            date_str = checkin["date"]
            # Format the date to be more readable
            formatted_date = date_str.replace("-", "å¹´", 1).replace("-", "æœˆ", 1) + "æ—¥"
            context_type = "ç¾¤" if checkin.get("context") == "group" else "ç§"

            # Add conclusion if available
            if checkin.get("conclusion"):
                stats_msg += f"  {i+1}. {formatted_date} ({context_type})\n     å¤ç›˜ï¼š{checkin['conclusion']}\n"
            else:
                stats_msg += f"  {i+1}. {formatted_date} ({context_type})\n"
    else:
        stats_msg += "ğŸ“š æš‚æ— æ‰“å¡è®°å½•\n"

    await fupan_stats.finish(stats_msg)

# å¸®åŠ©å‘½ä»¤

fupan_help = on_command("å¤ç›˜å¸®åŠ©", aliases={"å¤ç›˜ help"})

@fupan_help.handle()
async def handle_fupan_help(uniinfo: Uninfo = Arg()):
    """å¤„ç†å¤ç›˜å¸®åŠ©å‘½ä»¤"""
    user_id = str(uniinfo.user.id) if uniinfo.user else "unknown"
    group_id = str(uniinfo.scene.id) if uniinfo.scene and uniinfo.scene.is_group else None
    context = "ç¾¤ç»„" if group_id else "ç§èŠ"

    help_msg = ("ğŸ“ˆ å¤ç›˜æ‰“å¡æ’ä»¶å¸®åŠ©\n"
                "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
                "ğŸ“ åŸºæœ¬å‘½ä»¤ï¼š\n"
                "  /å¤ç›˜ [å¤ç›˜ç»“è®º] | /æ‰“å¡ [å¤ç›˜ç»“è®º] | /ç­¾åˆ° [å¤ç›˜ç»“è®º] - æ¯æ—¥å¤ç›˜æ‰“å¡ï¼ˆå¯é™„åŠ ç»“è®ºï¼‰\n"
                "  /å¤ç›˜ç»Ÿè®¡ - ä¸ªäººæ‰“å¡ç»Ÿè®¡\n"
                "  /å¤ç›˜æ’è¡Œ - æ‰“å¡æ’è¡Œæ¦œ\n\n"
                "â†©ï¸ å…¶ä»–å‘½ä»¤ï¼š\n"
                "  /å¤ç›˜æ’¤é”€ | /æ’¤é”€å¤ç›˜ - æ’¤é”€æœ€åæ‰“å¡\n"
                f"  /å¤ç›˜é‡ç½® - é‡ç½®æ•°æ®ï¼ˆä»…è¶…çº§ç”¨æˆ·ï¼‰\n"
                f"  /å¤ç›˜å¸®åŠ© - æ˜¾ç¤ºæ­¤å¸®åŠ©\n\n"
                f"ç¤ºä¾‹ï¼š/å¤ç›˜ æˆ‘è§‰å¾—æ˜å¤©é«˜å¼€ä½èµ°\n"
                f"å½“å‰ç¯å¢ƒï¼š{context}\n"
                "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
                "ğŸ’¡ æ•°æ®åœ¨ç¾¤èŠå’Œç§èŠä¸­åˆ†å¼€ç»Ÿè®¡")

    await fupan_help.finish(help_msg)


@fupan_reset.handle()
async def handle_fupan_reset(args: Message = CommandArg(), uniinfo: Uninfo = Arg()):
    """å¤„ç†å¤ç›˜æ•°æ®é‡ç½®å‘½ä»¤"""
    user_id = str(uniinfo.user.id) if uniinfo.user else "unknown"
    group_id = str(uniinfo.scene.id) if uniinfo.scene and uniinfo.scene.is_group else None
    arg_text = args.extract_plain_text().strip()

    if arg_text == "ç§èŠ":
        # é‡ç½®æ‰€æœ‰ç§èŠæ•°æ®
        count = reset_all_dm_data()
        await fupan_reset.finish(f"âœ… å·²é‡ç½®æ‰€æœ‰ç§èŠç”¨æˆ·çš„å¤ç›˜æ•°æ®ï¼Œå…±é‡ç½® {count} ä½ç”¨æˆ·çš„è®°å½•")
    elif arg_text == "å½“å‰ç¾¤ç»„" and group_id:
        # é‡ç½®å½“å‰ç¾¤ç»„æ•°æ®
        count = reset_group_data(group_id)
        await fupan_reset.finish(f"âœ… å·²é‡ç½®ç¾¤ç»„ {group_id} çš„å¤ç›˜æ•°æ®ï¼Œå…±é‡ç½® {count} ä½ç”¨æˆ·çš„è®°å½•")
    elif arg_text.startswith("ç¾¤ç»„"):
        # é‡ç½®æŒ‡å®šç¾¤ç»„æ•°æ®
        target_group_id = arg_text[2:].strip()  # å»æ‰"ç¾¤ç»„"å‰ç¼€
        if target_group_id:
            count = reset_group_data(target_group_id)
            await fupan_reset.finish(f"âœ… å·²é‡ç½®ç¾¤ç»„ {target_group_id} çš„å¤ç›˜æ•°æ®ï¼Œå…±é‡ç½® {count} ä½ç”¨æˆ·çš„è®°å½•")
        else:
            await fupan_reset.finish("âŒ è¯·æä¾›è¦é‡ç½®çš„ç¾¤ç»„IDï¼Œä¾‹å¦‚ï¼š/å¤ç›˜é‡ç½® ç¾¤ç»„123456")
    else:
        context = "å½“å‰ç¾¤ç»„" if group_id else "ç§èŠ"
        await fupan_reset.finish(f"ğŸ“ˆ å¤ç›˜æ•°æ®é‡ç½®å‘½ä»¤\n"
                                 f"ç”¨æ³•ï¼š\n"
                                 f"  /å¤ç›˜é‡ç½® ç§èŠ - é‡ç½®æ‰€æœ‰ç§èŠç”¨æˆ·æ•°æ®\n"
                                 f"  /å¤ç›˜é‡ç½® å½“å‰{context} - é‡ç½®{context}æ•°æ®\n"
                                 f"  /å¤ç›˜é‡ç½® ç¾¤ç»„<ç¾¤å·> - é‡ç½®æŒ‡å®šç¾¤ç»„æ•°æ®\n"
                                 f"âš ï¸ æ³¨æ„ï¼šæ­¤æ“ä½œä¸å¯é€†ï¼Œè¯·è°¨æ…ä½¿ç”¨ï¼")

@fupan_rank.handle()
async def handle_fupan_rank(uniinfo: Uninfo = Arg()):
    """å¤„ç†å¤ç›˜æ’è¡Œå‘½ä»¤"""
    user_id = str(uniinfo.user.id) if uniinfo.user else "unknown"
    group_id = str(uniinfo.scene.id) if uniinfo.scene and uniinfo.scene.is_group else None
    all_files = get_all_checkin_files()
    rank_data = []

    # æ ¹æ®å½“å‰ç¯å¢ƒè¿‡æ»¤æ–‡ä»¶ï¼ˆç¾¤ç»„æˆ–ç§èŠï¼‰
    context_suffix = f"_group_{group_id}.json" if group_id else "_dm.json"

    for file_path in all_files:
        # åªå¤„ç†ä¸å½“å‰ç¯å¢ƒåŒ¹é…çš„æ–‡ä»¶
        if (group_id and f"_group_{group_id}.json" in file_path.name) or \
           (not group_id and file_path.name.endswith("_dm.json")):
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                # Ensure strike_count field exists for backward compatibility
                if "strike_count" not in data:
                    data["strike_count"] = 0
                rank_data.append({
                    "user_id": data["user_id"],
                    "nickname": data.get("nickname", data["user_id"]) or data["user_id"],
                    "count": data["strike_count"]  # Use strike count for ranking
                })

    # æŒ‰è¿ç»­æ‰“å¡æ¬¡æ•°æ’åº
    rank_data.sort(key=lambda x: x["count"], reverse=True)

    context = "ç¾¤ç»„" if group_id else "ç§èŠ"
    rank_msg = f"ğŸ† {context}å¤ç›˜è¿ç»­æ‰“å¡æ’è¡Œ\n"
    rank_msg += f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"

    if not rank_data:
        rank_msg += "  æš‚æ— æ•°æ®\n"
    else:
        for i, data in enumerate(rank_data[:10], 1):  # æ˜¾ç¤ºå‰10å
            # å¦‚æœnicknameä¸user_idç›¸åŒæˆ–ä¸ºç©ºï¼Œæ˜¾ç¤º"ç”¨æˆ·{user_id}"æ ¼å¼
            if not data['nickname'] or data['nickname'] == data['user_id']:
                display_name = f"ç”¨æˆ·{data['user_id']}"
            else:
                display_name = data['nickname']
            rank_msg += f"  {i}. {display_name}: {data['count']}è¿å‡»\n"

    rank_msg += f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

    await fupan_rank.finish(rank_msg)


@fupan_revoke.handle()
async def handle_fupan_revoke(uniinfo: Uninfo = Arg()):
    """å¤„ç†æ’¤é”€å¤ç›˜æ‰“å¡å‘½ä»¤"""
    # è·å–ç”¨æˆ·ä¿¡æ¯
    user_id = str(uniinfo.user.id) if uniinfo.user else "unknown"
    group_id = str(uniinfo.scene.id) if uniinfo.scene and uniinfo.scene.is_group else None

    # åŠ è½½ç”¨æˆ·æ•°æ®
    user_data = load_user_checkin_data(user_id, group_id)

    # æ£€æŸ¥æ˜¯å¦æœ‰æ‰“å¡è®°å½•
    if not user_data["checkins"]:
        await fupan_revoke.finish("æ‚¨è¿˜æ²¡æœ‰ä»»ä½•æ‰“å¡è®°å½•ï¼Œæ— éœ€æ’¤é”€")

    # è·å–æœ€åä¸€ä¸ªæ‰“å¡è®°å½•
    last_checkin = user_data["checkins"][-1]
    last_checkin_date = last_checkin["date"]
    # Convert timestamp to readable time format
    last_checkin_timestamp = last_checkin["timestamp"]
    last_checkin_time = datetime.fromtimestamp(last_checkin_timestamp).strftime("%Y-%m-%d %H:%M:%S")

    # ç§»é™¤æœ€åä¸€ä¸ªæ‰“å¡è®°å½•
    user_data["checkins"].pop()
    user_data["total_count"] = len(user_data["checkins"])

    # Recalculate strike count after revoking
    # For simplicity in this less frequent operation, we'll recalculate using the full sequence
    if len(user_data["checkins"]) > 0:
        user_data["strike_count"] = calculate_simple_strike_count(user_data["checkins"])
    else:
        # No check-ins left, reset strike count
        user_data["strike_count"] = 0

    # ä¿å­˜æ›´æ–°åçš„æ•°æ®
    save_user_checkin_data(user_id, user_data, group_id)

    # å‘é€æˆåŠŸæ¶ˆæ¯
    strike_count = user_data.get("strike_count", 0)
    revoke_msg = (f"âœ… å·²æˆåŠŸæ’¤é”€æœ€åä¸€æ¬¡å¤ç›˜æ‰“å¡\n"
                  f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                  f"  æ’¤é”€è®°å½•ï¼š{last_checkin_date} {last_checkin_time}\n"
                  f"  å½“å‰ç´¯è®¡æ‰“å¡ï¼š{user_data['total_count']}æ¬¡\n"
                  f"  è¿ç»­æ‰“å¡ï¼š{strike_count}è¿å‡»\n"
                  f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    await fupan_revoke.finish(revoke_msg)


def calculate_simple_strike_count(checkins: list) -> int:
    """
    Calculate strike count based on consecutive trading days.
    This is a simplified version that's called when needed, not for every operation.

    Args:
        checkins: All check-ins for the user

    Returns:
        Strike count (consecutive trading days)
    """
    if not checkins:
        return 0

    # Get all unique trading days that were checked in for
    trading_days_checked_in = list({c.get("trading_day") for c in checkins if c.get("trading_day")})

    if not trading_days_checked_in:
        return 0

    # Convert to date objects and sort
    trading_day_dates = [datetime.strptime(day, "%Y-%m-%d").date() for day in trading_days_checked_in]
    trading_day_dates.sort()

    # Count consecutive trading days from the most recent
    strike_count = 0
    current_date = trading_day_dates[-1]

    # Go backwards from the most recent trading day
    for trading_day in reversed(trading_day_dates):
        # If this is the first iteration or the trading day is consecutive
        if strike_count == 0 or (current_date - trading_day).days == 1:
            strike_count += 1
            current_date = trading_day
        else:
            # Break if not consecutive
            break

    return strike_count